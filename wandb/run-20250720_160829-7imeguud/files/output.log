Calculating target architecture based on schedule...

============================================================
       TARGET MODEL ARCHITECTURE (at end of schedule)
============================================================
  n_layer                | 6
  n_head                 | 12
  n_embd                 | 768
  n_hidden               | 1536
  block_size             | 1024
  vocab_size             | 50304
  dropout                | 0.0
  bias                   | False
  embedding_mode         | standard
  attn_lora_rank         | 0
  embedding_rank         | 0
  lora_alpha             | 0.0
============================================================


============================================================
           INITIAL MODEL ARCHITECTURE (at Iter 0)
============================================================
  n_layer                | 3
  n_head                 | 12
  n_embd                 | 768
  n_hidden               | 768
  block_size             | 1024
  vocab_size             | 50304
  dropout                | 0.0
  bias                   | False
  embedding_mode         | lora
  attn_lora_rank         | 48
  embedding_rank         | 48
  lora_alpha             | 1.0
============================================================


Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
eval every:100
step 0: train loss 10.9678, val loss 10.9694
--- Model Analysis ---
  MLP Rank Utilization (L0): 71.09% (546/768)
--- Model Analysis ---
  Attention Rank Utilization (L0): 91.93% (706/768)
--- Model Analysis ---
  MLP Rank Utilization (L1): 71.09% (546/768)
--- Model Analysis ---
  Attention Rank Utilization (L1): 91.93% (706/768)
--- Model Analysis ---
  MLP Rank Utilization (L2): 71.22% (547/768)
--- Model Analysis ---
  Attention Rank Utilization (L2): 91.93% (706/768)
--- Model Analysis ---
  Embedding Utilization (L2): 97.53% (749/768)
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 757, in <module>
    avg_entropy = analyzer.analyze_attention_entropy(X_val)
NameError: name 'X_val' is not defined. Did you mean: 'eval'?
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 757, in <module>
    avg_entropy = analyzer.analyze_attention_entropy(X_val)
NameError: name 'X_val' is not defined. Did you mean: 'eval'?
