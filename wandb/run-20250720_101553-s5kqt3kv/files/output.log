
Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
step 0: train loss 10.9685, val loss 10.9694
iter 0: loss 10.9656, lr 0.00005, time 6911.64ms, mfu -100.00%
iter 10: loss 9.6157, lr 0.00055, time 538.61ms, mfu 34.31%
iter 20: loss 9.4234, lr 0.00104, time 543.87ms, mfu 34.28%
iter 30: loss 9.3047, lr 0.00154, time 552.82ms, mfu 34.19%
iter 40: loss 9.1775, lr 0.00204, time 559.11ms, mfu 34.08%
iter 50: loss 9.0495, lr 0.00254, time 560.60ms, mfu 33.97%
iter 60: loss 8.8651, lr 0.00303, time 567.08ms, mfu 33.83%
iter 70: loss 8.7746, lr 0.00353, time 569.45ms, mfu 33.69%
iter 80: loss 8.7000, lr 0.00403, time 568.52ms, mfu 33.57%
iter 90: loss 8.6671, lr 0.00453, time 579.36ms, mfu 33.41%
step 100: train loss 8.5846, val loss 8.5888
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Timeout
Current val loss: 8.5888, Trigger loss: 1.0000
Iterations since last op: 100, Max wait: 100
Executing operation: merge_lora_weights  with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 17, with 8,202,240 parameters
num non-decayed parameter tensors: 7, with 5,376 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 28 parameters
Re-compiling the model...
Architectural operation completed successfully.
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_lr
Trigger reason: Loss threshold
Current val loss: 8.5888, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_lr  with value: 0.5
LR multiplier: 10.0000 -> 5.0000
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: reset_lr_schedule
Trigger reason: Loss threshold
Current val loss: 8.5888, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: reset_lr_schedule  with value: None
LR schedule offset: 0 -> 100
=== SCALING OPERATION COMPLETE ===

iter 100: loss 8.6253, lr 0.00502, time 4997.01ms, mfu 30.44%
iter 110: loss 8.4380, lr 0.00027, time 570.16ms, mfu 30.63%
iter 120: loss 8.4191, lr 0.00052, time 583.34ms, mfu 30.74%
iter 130: loss 8.4581, lr 0.00077, time 585.00ms, mfu 30.82%
iter 140: loss 8.3586, lr 0.00102, time 576.32ms, mfu 30.95%
iter 150: loss 8.3357, lr 0.00127, time 577.85ms, mfu 31.05%
iter 160: loss 8.2587, lr 0.00152, time 568.62ms, mfu 31.20%
iter 170: loss 8.2374, lr 0.00177, time 574.78ms, mfu 31.29%
iter 180: loss 8.2409, lr 0.00201, time 576.33ms, mfu 31.37%
iter 190: loss 8.0930, lr 0.00226, time 570.13ms, mfu 31.47%
step 200: train loss 8.1024, val loss 8.1377
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Timeout
Current val loss: 8.1377, Trigger loss: 1.0000
Iterations since last op: 100, Max wait: 100
Executing operation: merge_lora_weights  with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 17, with 8,202,240 parameters
num non-decayed parameter tensors: 7, with 5,376 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 28 parameters
Re-compiling the model...
Architectural operation completed successfully.
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_warmup_iters
Trigger reason: Loss threshold
Current val loss: 8.1377, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_warmup_iters  with value: 2.0
Warmup iters multiplier: 1.0000 -> 2.0000
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: reset_lr_schedule
Trigger reason: Loss threshold
Current val loss: 8.1377, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: reset_lr_schedule  with value: None
LR schedule offset: 100 -> 200
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_batch_size
Trigger reason: Loss threshold
Current val loss: 8.1377, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_batch_size  with value: 0.5
Batch size: 32 -> 16
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_grad_accum
Trigger reason: Loss threshold
Current val loss: 8.1377, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_grad_accum  with value: 2.0
Grad accum steps: 2 -> 4
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_lr
Trigger reason: Loss threshold
Current val loss: 8.1377, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_lr  with value: 0.5
LR multiplier: 5.0000 -> 2.5000
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: reset_lr_schedule
Trigger reason: Loss threshold
Current val loss: 8.1377, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: reset_lr_schedule  with value: None
LR schedule offset: 200 -> 200
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: stack_layers
Trigger reason: Loss threshold
Current val loss: 8.1377, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: stack_layers  with value: 2
Performing architectural operation: stack_layers
Stacking layers: current depth 3, creating 6 total layers.
Model now has 6 layers.

Detailed parameter count:
  total                  | Total:   63,213,312 | Trainable:   13,963,008
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:   15,040,512 | Trainable:    4,423,680
  feed_forward_layers    | Total:    7,077,888 | Trainable:    7,077,888
  layer_norms            | Total:        9,216 | Trainable:        9,216
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 32, with 13,953,024 parameters
num non-decayed parameter tensors: 13, with 9,984 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 52 parameters
Re-compiling the model...
Architectural operation completed successfully.
Re-evaluating validation loss after operation...
New val loss after operation: 8.9166
iter 200: loss 8.8698, lr 0.00251, time 19822.80ms, mfu 28.45%
iter 210: loss 8.4061, lr 0.00007, time 748.08ms, mfu 28.76%
iter 220: loss 8.1963, lr 0.00013, time 763.20ms, mfu 28.97%
iter 230: loss 8.1600, lr 0.00019, time 763.94ms, mfu 29.17%
iter 240: loss 8.1961, lr 0.00026, time 775.10ms, mfu 29.30%
iter 250: loss 8.3005, lr 0.00032, time 766.81ms, mfu 29.45%
iter 260: loss 7.9142, lr 0.00038, time 766.86ms, mfu 29.58%
iter 270: loss 7.9197, lr 0.00044, time 759.28ms, mfu 29.73%
iter 280: loss 7.9944, lr 0.00050, time 756.08ms, mfu 29.88%
iter 290: loss 7.9942, lr 0.00057, time 753.91ms, mfu 30.02%
step 300: train loss 8.0430, val loss 8.0239
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Timeout
Current val loss: 8.0239, Trigger loss: 1.0000
Iterations since last op: 100, Max wait: 100
Executing operation: merge_lora_weights  with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   63,213,312 | Trainable:   13,963,008
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:   15,040,512 | Trainable:    4,423,680
  feed_forward_layers    | Total:    7,077,888 | Trainable:    7,077,888
  layer_norms            | Total:        9,216 | Trainable:        9,216
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 32, with 13,953,024 parameters
num non-decayed parameter tensors: 13, with 9,984 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 52 parameters
Re-compiling the model...
Architectural operation completed successfully.
=== SCALING OPERATION COMPLETE ===

iter 300: loss 8.0039, lr 0.00063, time 3492.50ms, mfu 27.70%
iter 310: loss 8.0784, lr 0.00069, time 754.93ms, mfu 28.06%
iter 320: loss 7.9248, lr 0.00075, time 756.28ms, mfu 28.37%
iter 330: loss 7.9260, lr 0.00082, time 756.90ms, mfu 28.65%
iter 340: loss 7.8745, lr 0.00088, time 758.45ms, mfu 28.90%
iter 350: loss 8.0445, lr 0.00094, time 761.85ms, mfu 29.11%
iter 360: loss 7.6819, lr 0.00100, time 761.54ms, mfu 29.30%
iter 370: loss 7.8567, lr 0.00107, time 759.92ms, mfu 29.48%
iter 380: loss 7.8456, lr 0.00113, time 766.04ms, mfu 29.61%
iter 390: loss 7.7790, lr 0.00119, time 764.27ms, mfu 29.74%
step 400: train loss 7.7862, val loss 7.7761
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Timeout
Current val loss: 7.7761, Trigger loss: 1.0000
Iterations since last op: 100, Max wait: 100
Executing operation: merge_lora_weights  with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   63,213,312 | Trainable:   13,963,008
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:   15,040,512 | Trainable:    4,423,680
  feed_forward_layers    | Total:    7,077,888 | Trainable:    7,077,888
  layer_norms            | Total:        9,216 | Trainable:        9,216
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 32, with 13,953,024 parameters
num non-decayed parameter tensors: 13, with 9,984 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 52 parameters
Re-compiling the model...
Architectural operation completed successfully.
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_batch_size
Trigger reason: Loss threshold
Current val loss: 7.7761, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_batch_size  with value: 0.5
Batch size: 16 -> 8
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_grad_accum
Trigger reason: Loss threshold
Current val loss: 7.7761, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_grad_accum  with value: 2.0
Grad accum steps: 4 -> 8
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: stack_layers
Trigger reason: Loss threshold
Current val loss: 7.7761, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: stack_layers  with value: 2
Performing architectural operation: stack_layers
Stacking layers: current depth 6, creating 12 total layers.
Model now has 12 layers.

Detailed parameter count:
  total                  | Total:   85,340,928 | Trainable:   25,473,792
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:   30,081,024 | Trainable:    8,847,360
  feed_forward_layers    | Total:   14,155,776 | Trainable:   14,155,776
  layer_norms            | Total:       18,432 | Trainable:       18,432
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 62, with 25,454,592 parameters
num non-decayed parameter tensors: 25, with 19,200 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 100 parameters
Re-compiling the model...
Architectural operation completed successfully.
Re-evaluating validation loss after operation...
New val loss after operation: 8.1275
iter 400: loss 7.8447, lr 0.00125, time 29789.80ms, mfu 26.88%
iter 410: loss 7.9827, lr 0.00132, time 1142.07ms, mfu 27.16%
iter 420: loss 8.0119, lr 0.00138, time 1154.60ms, mfu 27.37%
iter 430: loss 7.5819, lr 0.00144, time 1160.45ms, mfu 27.55%
iter 440: loss 7.7188, lr 0.00150, time 1139.32ms, mfu 27.77%
iter 450: loss 7.6813, lr 0.00156, time 1128.67ms, mfu 28.00%
iter 460: loss 7.4539, lr 0.00163, time 1138.62ms, mfu 28.17%
iter 470: loss 7.6233, lr 0.00169, time 1128.84ms, mfu 28.35%
iter 480: loss 7.5184, lr 0.00175, time 1136.15ms, mfu 28.50%
iter 490: loss 7.6426, lr 0.00181, time 1141.24ms, mfu 28.62%
step 500: train loss 7.6332, val loss 7.6565
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_lr
Trigger reason: Loss threshold
Current val loss: 7.6565, Trigger loss: 100.0000
Iterations since last op: 100, Max wait: 1
Executing operation: change_lr  with value: 0.5
LR multiplier: 2.5000 -> 1.2500
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: reset_lr_schedule
Trigger reason: Loss threshold
Current val loss: 7.6565, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: reset_lr_schedule  with value: None
LR schedule offset: 200 -> 500
=== SCALING OPERATION COMPLETE ===

iter 500: loss 7.8233, lr 0.00188, time 3639.30ms, mfu 26.69%
iter 510: loss 7.4790, lr 0.00003, time 1157.10ms, mfu 26.94%
iter 520: loss 7.7165, lr 0.00007, time 1143.97ms, mfu 27.21%
iter 530: loss 7.6897, lr 0.00010, time 1158.06ms, mfu 27.41%
iter 540: loss 7.5735, lr 0.00013, time 1153.58ms, mfu 27.61%
iter 550: loss 7.2542, lr 0.00016, time 1152.81ms, mfu 27.78%
iter 560: loss 7.3201, lr 0.00019, time 1144.32ms, mfu 27.97%
iter 570: loss 7.4254, lr 0.00022, time 1154.02ms, mfu 28.10%
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 654, in <module>
    scaler.scale(loss).backward()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 654, in <module>
    scaler.scale(loss).backward()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7795865c8b80>
Traceback (most recent call last):
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/wandb/sdk/lib/service/service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/wandb/sdk/lib/service/service_connection.py", line 182, in teardown
    self._router.join()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt:
Exception ignored in atexit callback: <function shutdown_compile_workers at 0x7795b7798670>
Traceback (most recent call last):
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 113, in shutdown_compile_workers
    pool.shutdown()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 239, in shutdown
    self.process.wait(300)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/subprocess.py", line 1937, in _wait
    time.sleep(delay)
KeyboardInterrupt:
