
Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
step 0: train loss 10.9660, val loss 10.9694
iter 0: loss 10.9657, lr 0.00000, time 7412.93ms, mfu -100.00%
iter 10: loss 10.1329, lr 0.00003, time 543.42ms, mfu 34.01%
iter 20: loss 9.6550, lr 0.00006, time 551.86ms, mfu 33.96%
iter 30: loss 9.6087, lr 0.00009, time 552.93ms, mfu 33.90%
iter 40: loss 9.4938, lr 0.00012, time 550.40ms, mfu 33.87%
iter 50: loss 9.3026, lr 0.00015, time 563.36ms, mfu 33.76%
iter 60: loss 9.2735, lr 0.00018, time 562.03ms, mfu 33.68%
iter 70: loss 9.1127, lr 0.00021, time 567.70ms, mfu 33.56%
iter 80: loss 9.0353, lr 0.00024, time 577.56ms, mfu 33.41%
iter 90: loss 9.0385, lr 0.00027, time 575.93ms, mfu 33.27%
step 100: train loss 8.9402, val loss 8.9961
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Timeout
Current val loss: 8.9961, Trigger loss: 1.0000
Iterations since last op: 100, Max wait: 100
Executing operation: merge_lora_weights with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 17, with 8,202,240 parameters
num non-decayed parameter tensors: 7, with 5,376 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 28 parameters
Re-compiling the model...
Architectural operation completed successfully.
Re-evaluating validation loss after operation...
New val loss after operation: 8.9470
iter 100: loss 8.9514, lr 0.00030, time 7270.16ms, mfu 30.20%
iter 110: loss 8.9363, lr 0.00033, time 590.36ms, mfu 30.31%
iter 120: loss 8.9438, lr 0.00036, time 591.47ms, mfu 30.40%
iter 130: loss 8.8773, lr 0.00039, time 588.36ms, mfu 30.51%
iter 140: loss 8.8638, lr 0.00042, time 586.95ms, mfu 30.60%
iter 150: loss 8.8573, lr 0.00045, time 583.55ms, mfu 30.71%
iter 160: loss 8.7770, lr 0.00048, time 581.01ms, mfu 30.82%
iter 170: loss 8.7641, lr 0.00051, time 578.08ms, mfu 30.93%
iter 180: loss 8.8453, lr 0.00054, time 576.51ms, mfu 31.05%
iter 190: loss 8.6567, lr 0.00057, time 572.10ms, mfu 31.17%
step 200: train loss 8.6592, val loss 8.6917
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Timeout
Current val loss: 8.6917, Trigger loss: 1.0000
Iterations since last op: 100, Max wait: 100
Executing operation: merge_lora_weights with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 17, with 8,202,240 parameters
num non-decayed parameter tensors: 7, with 5,376 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 28 parameters
Re-compiling the model...
Architectural operation completed successfully.
Re-evaluating validation loss after operation...
New val loss after operation: 8.6834
iter 200: loss 8.5323, lr 0.00060, time 7135.98ms, mfu 28.31%
iter 210: loss 8.7037, lr 0.00060, time 576.50ms, mfu 28.69%
iter 220: loss 8.6267, lr 0.00060, time 577.11ms, mfu 29.02%
iter 230: loss 8.7072, lr 0.00060, time 580.64ms, mfu 29.30%
iter 240: loss 8.7217, lr 0.00060, time 579.21ms, mfu 29.56%
iter 250: loss 8.5090, lr 0.00060, time 580.73ms, mfu 29.79%
iter 260: loss 8.5160, lr 0.00060, time 586.31ms, mfu 29.96%
iter 270: loss 8.5436, lr 0.00060, time 581.96ms, mfu 30.14%
iter 280: loss 8.5602, lr 0.00060, time 587.76ms, mfu 30.27%
iter 290: loss 8.5050, lr 0.00060, time 585.44ms, mfu 30.40%
step 300: train loss 8.5383, val loss 8.5256
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Timeout
Current val loss: 8.5256, Trigger loss: 1.0000
Iterations since last op: 100, Max wait: 100
Executing operation: merge_lora_weights with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 17, with 8,202,240 parameters
num non-decayed parameter tensors: 7, with 5,376 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 28 parameters
Re-compiling the model...
Architectural operation completed successfully.
Re-evaluating validation loss after operation...
New val loss after operation: 8.5423
iter 300: loss 8.5130, lr 0.00060, time 6943.16ms, mfu 27.63%
iter 310: loss 8.5709, lr 0.00060, time 584.81ms, mfu 28.02%
iter 320: loss 8.5152, lr 0.00060, time 582.32ms, mfu 28.40%
iter 330: loss 8.6127, lr 0.00060, time 583.14ms, mfu 28.73%
iter 340: loss 8.4761, lr 0.00060, time 583.99ms, mfu 29.02%
iter 350: loss 8.5714, lr 0.00060, time 582.30ms, mfu 29.29%
iter 360: loss 8.5086, lr 0.00060, time 579.71ms, mfu 29.55%
iter 370: loss 8.5429, lr 0.00060, time 575.31ms, mfu 29.81%
iter 380: loss 8.3675, lr 0.00060, time 580.01ms, mfu 30.01%
iter 390: loss 8.4549, lr 0.00060, time 579.39ms, mfu 30.20%
step 400: train loss 8.5142, val loss 8.4540
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Timeout
Current val loss: 8.4540, Trigger loss: 1.0000
Iterations since last op: 100, Max wait: 100
Executing operation: merge_lora_weights with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 17, with 8,202,240 parameters
num non-decayed parameter tensors: 7, with 5,376 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 28 parameters
Re-compiling the model...
Architectural operation completed successfully.
Re-evaluating validation loss after operation...
New val loss after operation: 8.4790
iter 400: loss 8.3594, lr 0.00060, time 7310.34ms, mfu 27.43%
iter 410: loss 8.5658, lr 0.00060, time 579.24ms, mfu 27.88%
iter 420: loss 8.4410, lr 0.00060, time 581.45ms, mfu 28.27%
iter 430: loss 8.4561, lr 0.00060, time 582.29ms, mfu 28.62%
iter 440: loss 8.4801, lr 0.00060, time 577.57ms, mfu 28.96%
iter 450: loss 8.3055, lr 0.00060, time 581.13ms, mfu 29.24%
iter 460: loss 8.3056, lr 0.00060, time 584.41ms, mfu 29.48%
iter 470: loss 8.2563, lr 0.00060, time 586.74ms, mfu 29.68%
iter 480: loss 8.2652, lr 0.00060, time 581.73ms, mfu 29.89%
iter 490: loss 8.3414, lr 0.00060, time 584.64ms, mfu 30.06%
step 500: train loss 8.3071, val loss 8.3166
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Timeout
Current val loss: 8.3166, Trigger loss: 1.0000
Iterations since last op: 100, Max wait: 100
Executing operation: merge_lora_weights with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 17, with 8,202,240 parameters
num non-decayed parameter tensors: 7, with 5,376 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 28 parameters
Re-compiling the model...
Architectural operation completed successfully.
Re-evaluating validation loss after operation...
New val loss after operation: 8.3190
iter 500: loss 8.2899, lr 0.00060, time 7223.68ms, mfu 27.31%
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 635, in <module>
    scaler.scale(loss).backward()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 635, in <module>
    scaler.scale(loss).backward()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x724277f70820>
Traceback (most recent call last):
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/wandb/sdk/lib/service/service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/wandb/sdk/lib/service/service_connection.py", line 182, in teardown
    self._router.join()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt:
Exception ignored in atexit callback: <function shutdown_compile_workers at 0x7242b0694550>
Traceback (most recent call last):
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 113, in shutdown_compile_workers
    pool.shutdown()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 239, in shutdown
    self.process.wait(300)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/subprocess.py", line 1937, in _wait
    time.sleep(delay)
KeyboardInterrupt:
