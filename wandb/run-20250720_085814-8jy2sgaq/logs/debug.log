2025-07-20 08:58:14,523 INFO    MainThread:124133 [wandb_setup.py:_flush():80] Current SDK version is 0.21.0
2025-07-20 08:58:14,523 INFO    MainThread:124133 [wandb_setup.py:_flush():80] Configure stats pid to 124133
2025-07-20 08:58:14,523 INFO    MainThread:124133 [wandb_setup.py:_flush():80] Loading settings from /teamspace/studios/this_studio/.config/wandb/settings
2025-07-20 08:58:14,523 INFO    MainThread:124133 [wandb_setup.py:_flush():80] Loading settings from /teamspace/studios/this_studio/nanoGPT/wandb/settings
2025-07-20 08:58:14,524 INFO    MainThread:124133 [wandb_setup.py:_flush():80] Loading settings from environment variables
2025-07-20 08:58:14,524 INFO    MainThread:124133 [wandb_init.py:setup_run_log_directory():703] Logging user logs to /teamspace/studios/this_studio/nanoGPT/wandb/run-20250720_085814-8jy2sgaq/logs/debug.log
2025-07-20 08:58:14,524 INFO    MainThread:124133 [wandb_init.py:setup_run_log_directory():704] Logging internal logs to /teamspace/studios/this_studio/nanoGPT/wandb/run-20250720_085814-8jy2sgaq/logs/debug-internal.log
2025-07-20 08:58:14,524 INFO    MainThread:124133 [wandb_init.py:init():830] calling init triggers
2025-07-20 08:58:14,524 INFO    MainThread:124133 [wandb_init.py:init():835] wandb.init called with sweep_config: {}
config: {'out_dir': 'out', 'eval_interval': 100, 'log_interval': 10, 'eval_iters': 10, 'eval_only': False, 'always_save_checkpoint': True, 'init_from': 'scratch', 'log_dir': 'logs', 'file_logging': True, 'wandb_log': True, 'wandb_project': 'owt', 'wandb_run_name': 'gpt2-124M-LoRA-Expansion-Growth', 'dataset': 'fineweb10B', 'gradient_accumulation_steps': 2, 'batch_size': 32, 'block_size': 1024, 'n_layer': 3, 'n_head': 12, 'n_embd': 768, 'dropout': 0.0, 'bias': False, 'use_rotary_embeddings': True, 'rotary_base': 10000.0, 'rotary_max_position_embeddings': 2048, 'learning_rate': 0.001, 'max_iters': 600000, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 200, 'lr_decay_iters': 600000, 'min_lr': 6e-05, 'backend': 'nccl', 'device': 'cuda', 'dtype': 'bfloat16', 'compile': True, 'embedding_mode': 'lora', 'attn_lora_rank': 48, 'embedding_rank': 48, 'lora_alpha': 1.0, 'attn_lora_rank_divisor': 16, 'vocab_lora_rank_divisor': 16, 'lora_alpha_multiplier': 1.0, 'n_layer_divisor': 1.0, 'n_hidden_divisor': 1.0, 'batch_size_multiplier': 1.0, 'grad_accum_multiplier': 1.0, 'lr_multiplier': 10, 'warmup_iters_multiplier': 1.0, 'eval_iters_multiplier': 1.0, 'eval_interval_multiplier': 1.0, '_wandb': {}}
2025-07-20 08:58:14,524 INFO    MainThread:124133 [wandb_init.py:init():871] starting backend
2025-07-20 08:58:14,732 INFO    MainThread:124133 [wandb_init.py:init():874] sending inform_init request
2025-07-20 08:58:14,737 INFO    MainThread:124133 [wandb_init.py:init():882] backend started and connected
2025-07-20 08:58:14,739 INFO    MainThread:124133 [wandb_init.py:init():953] updated telemetry
2025-07-20 08:58:14,753 INFO    MainThread:124133 [wandb_init.py:init():977] communicating run to backend with 90.0 second timeout
2025-07-20 08:58:15,010 INFO    MainThread:124133 [wandb_init.py:init():1029] starting run threads in backend
2025-07-20 08:58:15,227 INFO    MainThread:124133 [wandb_run.py:_console_start():2458] atexit reg
2025-07-20 08:58:15,227 INFO    MainThread:124133 [wandb_run.py:_redirect():2306] redirect: wrap_raw
2025-07-20 08:58:15,228 INFO    MainThread:124133 [wandb_run.py:_redirect():2375] Wrapping output streams.
2025-07-20 08:58:15,228 INFO    MainThread:124133 [wandb_run.py:_redirect():2398] Redirects installed.
2025-07-20 08:58:15,230 INFO    MainThread:124133 [wandb_init.py:init():1075] run started, returning control to user process
2025-07-20 08:59:13,237 INFO    MsgRouterThr:124133 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
