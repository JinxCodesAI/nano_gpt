
Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
step 0: train loss 10.9673, val loss 10.9694
iter 0: loss 10.9817, lr 0.00005, time 6860.08ms, mfu -100.00%
iter 10: loss 9.5961, lr 0.00055, time 540.67ms, mfu 34.18%
iter 20: loss 9.5766, lr 0.00104, time 547.89ms, mfu 34.14%
iter 30: loss 9.3089, lr 0.00154, time 559.78ms, mfu 34.02%
iter 40: loss 9.2470, lr 0.00204, time 560.67ms, mfu 33.92%
iter 50: loss 9.0276, lr 0.00254, time 561.92ms, mfu 33.81%
iter 60: loss 8.9382, lr 0.00303, time 577.35ms, mfu 33.63%
iter 70: loss 8.7676, lr 0.00353, time 576.99ms, mfu 33.47%
iter 80: loss 8.7353, lr 0.00403, time 583.33ms, mfu 33.29%
iter 90: loss 8.5791, lr 0.00453, time 581.96ms, mfu 33.14%
step 100: train loss 8.5752, val loss 8.5843
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Timeout
Current val loss: 8.5843, Trigger loss: 1.0000
Iterations since last op: 100, Max wait: 100
Executing operation: merge_lora_weights with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 17, with 8,202,240 parameters
num non-decayed parameter tensors: 7, with 5,376 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 28 parameters
Re-compiling the model...
Architectural operation completed successfully.
Re-evaluating validation loss after operation...
New val loss after operation: 8.5610
iter 100: loss 8.6205, lr 0.00502, time 7216.92ms, mfu 30.08%
iter 110: loss 8.7303, lr 0.00552, time 586.91ms, mfu 30.22%
iter 120: loss 8.5083, lr 0.00602, time 583.75ms, mfu 30.37%
iter 130: loss 8.3776, lr 0.00652, time 580.14ms, mfu 30.52%
iter 140: loss 8.3187, lr 0.00701, time 577.72ms, mfu 30.66%
iter 150: loss 8.3497, lr 0.00751, time 577.68ms, mfu 30.80%
iter 160: loss 8.1572, lr 0.00801, time 580.25ms, mfu 30.90%
iter 170: loss 8.1411, lr 0.00851, time 579.41ms, mfu 31.00%
iter 180: loss 8.2019, lr 0.00900, time 581.60ms, mfu 31.08%
iter 190: loss 7.9915, lr 0.00950, time 580.77ms, mfu 31.15%
step 200: train loss 7.9882, val loss 7.9427
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_lr
Trigger reason: Loss threshold
Current val loss: 7.9427, Trigger loss: 100.0000
Iterations since last op: 100, Max wait: 1
Executing operation: change_lr with value: 0.5
LR multiplier: 10.0000 -> 5.0000
Re-evaluating validation loss after operation...
New val loss after operation: 7.9241
iter 200: loss 7.8724, lr 0.01000, time 7304.66ms, mfu 28.29%
iter 210: loss 7.8358, lr 0.00500, time 587.57ms, mfu 28.61%
iter 220: loss 7.8798, lr 0.00500, time 583.78ms, mfu 28.91%
iter 230: loss 7.7346, lr 0.00500, time 589.70ms, mfu 29.15%
iter 240: loss 7.8448, lr 0.00500, time 589.45ms, mfu 29.37%
iter 250: loss 7.6425, lr 0.00500, time 583.78ms, mfu 29.60%
iter 260: loss 7.7051, lr 0.00500, time 587.36ms, mfu 29.79%
iter 270: loss 7.6105, lr 0.00500, time 585.77ms, mfu 29.96%
iter 280: loss 7.7274, lr 0.00500, time 586.39ms, mfu 30.12%
iter 290: loss 7.6460, lr 0.00500, time 586.15ms, mfu 30.26%
step 300: train loss 7.5824, val loss 7.5679
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Timeout
Current val loss: 7.5679, Trigger loss: 1.0000
Iterations since last op: 100, Max wait: 100
Executing operation: merge_lora_weights with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 17, with 8,202,240 parameters
num non-decayed parameter tensors: 7, with 5,376 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 28 parameters
Re-compiling the model...
Architectural operation completed successfully.
Re-evaluating validation loss after operation...
New val loss after operation: 7.8940
iter 300: loss 7.8963, lr 0.00500, time 6991.04ms, mfu 27.50%
iter 310: loss 7.5414, lr 0.00500, time 584.61ms, mfu 27.91%
iter 320: loss 7.4775, lr 0.00500, time 584.24ms, mfu 28.28%
iter 330: loss 7.5960, lr 0.00500, time 587.80ms, mfu 28.60%
iter 340: loss 7.2672, lr 0.00500, time 587.83ms, mfu 28.88%
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 647, in <module>
    lossf = loss.item() * gradient_accumulation_steps
KeyboardInterrupt
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 647, in <module>
    lossf = loss.item() * gradient_accumulation_steps
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x73fdbca54820>
Traceback (most recent call last):
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/wandb/sdk/lib/service/service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/wandb/sdk/lib/service/service_connection.py", line 182, in teardown
    self._router.join()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt:
Exception ignored in atexit callback: <function shutdown_compile_workers at 0x73fdcd6a4550>
Traceback (most recent call last):
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 113, in shutdown_compile_workers
    pool.shutdown()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 239, in shutdown
    self.process.wait(300)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/subprocess.py", line 1937, in _wait
    time.sleep(delay)
KeyboardInterrupt:
