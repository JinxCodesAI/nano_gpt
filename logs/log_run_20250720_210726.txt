================================================================================
Training run started at 2025-07-20 21:07:26
================================================================================
Configuration:
----------------------------------------
always_save_checkpoint: False
attn_lora_rank: 0
attn_lora_rank_divisor: 0
backend: nccl
batch_size: 32
batch_size_multiplier: 1.0
beta1: 0.9
beta2: 0.95
bias: False
block_size: 1024
compile: True
dataset: fineweb10B
decay_lr: True
device: cuda
dropout: 0.0
dtype: bfloat16
embedding_mode: lora
embedding_rank: 0
eval_interval: 200
eval_interval_multiplier: 1.0
eval_iters: 1
eval_iters_multiplier: 1.0
eval_only: False
file_logging: True
grad_accum_multiplier: 1.0
grad_clip: 1.0
gradient_accumulation_steps: 2
init_from: scratch
learning_rate: 0.0001
log_dir: logs
log_interval: 10
lora_alpha: 1.0
lora_alpha_multiplier: 1.0
lr_decay_iters: 600000
lr_multiplier: 1
max_iters: 600000
min_lr: 6e-05
n_embd: 768
n_head: 12
n_hidden_divisor: 4
n_layer: 1
n_layer_divisor: 12
out_dir: out
rotary_base: 10000.0
rotary_max_position_embeddings: 2048
use_rotary_embeddings: True
vocab_lora_rank_divisor: 0
wandb_log: True
wandb_project: owt
wandb_run_name: gpt2
warmup_iters: 200
warmup_iters_multiplier: 1.0
weight_decay: 0.1
----------------------------------------
[2025-07-20 21:07:36] step 0: train loss 15.1461, val loss 15.1569
[2025-07-20 21:09:13] step 200: train loss 11.1120, val loss 11.1760
[2025-07-20 21:09:14] OPERATION_START: merge_lora_weights first burn | iter=200 | value=None | trigger=Timeout | val_loss=11.1760 | trigger_loss=4.0000 | max_wait=200
[2025-07-20 21:09:14] OPERATION_SUCCESS: merge_lora_weights | iter=200 | status=merged
[2025-07-20 21:10:50] step 400: train loss 8.0054, val loss 8.2813
[2025-07-20 21:10:51] OPERATION_START: merge_lora_weights first burn | iter=400 | value=None | trigger=Timeout | val_loss=8.2813 | trigger_loss=4.0000 | max_wait=200
[2025-07-20 21:10:51] OPERATION_SUCCESS: merge_lora_weights | iter=400 | status=merged
[2025-07-20 21:12:28] step 600: train loss 7.6129, val loss 7.8607
[2025-07-20 21:12:29] OPERATION_START: merge_lora_weights first burn | iter=600 | value=None | trigger=Timeout | val_loss=7.8607 | trigger_loss=4.0000 | max_wait=200
[2025-07-20 21:12:29] OPERATION_SUCCESS: merge_lora_weights | iter=600 | status=merged
[2025-07-20 21:14:06] step 800: train loss 7.4168, val loss 7.5630
[2025-07-20 21:14:07] OPERATION_START: merge_lora_weights first burn | iter=800 | value=None | trigger=Timeout | val_loss=7.5630 | trigger_loss=4.0000 | max_wait=200
[2025-07-20 21:14:07] OPERATION_SUCCESS: merge_lora_weights | iter=800 | status=merged
[2025-07-20 21:15:44] step 1000: train loss 7.2971, val loss 7.3755
[2025-07-20 21:15:45] OPERATION_START: merge_lora_weights first burn | iter=1000 | value=None | trigger=Timeout | val_loss=7.3755 | trigger_loss=4.0000 | max_wait=200
[2025-07-20 21:15:45] OPERATION_SUCCESS: merge_lora_weights | iter=1000 | status=merged
