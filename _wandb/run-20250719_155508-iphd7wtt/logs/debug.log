2025-07-19 15:55:08,856 INFO    MainThread:9735 [wandb_setup.py:_flush():80] Current SDK version is 0.21.0
2025-07-19 15:55:08,856 INFO    MainThread:9735 [wandb_setup.py:_flush():80] Configure stats pid to 9735
2025-07-19 15:55:08,856 INFO    MainThread:9735 [wandb_setup.py:_flush():80] Loading settings from /teamspace/studios/this_studio/.config/wandb/settings
2025-07-19 15:55:08,856 INFO    MainThread:9735 [wandb_setup.py:_flush():80] Loading settings from /teamspace/studios/this_studio/nanoGPT/wandb/settings
2025-07-19 15:55:08,856 INFO    MainThread:9735 [wandb_setup.py:_flush():80] Loading settings from environment variables
2025-07-19 15:55:08,856 INFO    MainThread:9735 [wandb_init.py:setup_run_log_directory():703] Logging user logs to /teamspace/studios/this_studio/nanoGPT/wandb/run-20250719_155508-iphd7wtt/logs/debug.log
2025-07-19 15:55:08,856 INFO    MainThread:9735 [wandb_init.py:setup_run_log_directory():704] Logging internal logs to /teamspace/studios/this_studio/nanoGPT/wandb/run-20250719_155508-iphd7wtt/logs/debug-internal.log
2025-07-19 15:55:08,857 INFO    MainThread:9735 [wandb_init.py:init():830] calling init triggers
2025-07-19 15:55:08,857 INFO    MainThread:9735 [wandb_init.py:init():835] wandb.init called with sweep_config: {}
config: {'out_dir': 'out', 'eval_interval': 1000, 'log_interval': 10, 'eval_iters': 200, 'eval_only': False, 'always_save_checkpoint': True, 'init_from': 'scratch', 'log_dir': 'logs', 'file_logging': True, 'wandb_log': True, 'wandb_project': 'owt', 'wandb_run_name': 'gpt2-124M-fast', 'dataset': 'fineweb10B', 'gradient_accumulation_steps': 40, 'batch_size': 1, 'block_size': 1024, 'n_layer': 12, 'n_head': 12, 'n_embd': 768, 'dropout': 0.0, 'bias': False, 'use_rotary_embeddings': True, 'rotary_base': 10000.0, 'rotary_max_position_embeddings': 2048, 'learning_rate': 0.0006, 'max_iters': 600000, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 2000, 'lr_decay_iters': 600000, 'min_lr': 6e-05, 'backend': 'nccl', 'device': 'cuda', 'dtype': 'bfloat16', 'compile': True, 'attn_lora_rank_divisor': 0, 'vocab_lora_rank_divisor': 0, 'lora_alpha_multiplier': 1.0, 'n_layer_divisor': 1.0, 'n_hidden_divisor': 1.0, 'batch_size_multiplier': 1.0, 'grad_accum_multiplier': 0.4, 'lr_multiplier': 10.0, 'warmup_iters_multiplier': 0.05, 'eval_iters_multiplier': 0.2, 'eval_interval_multiplier': 0.1, '_wandb': {}}
2025-07-19 15:55:08,857 INFO    MainThread:9735 [wandb_init.py:init():871] starting backend
2025-07-19 15:55:09,065 INFO    MainThread:9735 [wandb_init.py:init():874] sending inform_init request
2025-07-19 15:55:09,071 INFO    MainThread:9735 [wandb_init.py:init():882] backend started and connected
2025-07-19 15:55:09,073 INFO    MainThread:9735 [wandb_init.py:init():953] updated telemetry
2025-07-19 15:55:09,087 INFO    MainThread:9735 [wandb_init.py:init():977] communicating run to backend with 90.0 second timeout
2025-07-19 15:55:09,458 INFO    MainThread:9735 [wandb_init.py:init():1029] starting run threads in backend
2025-07-19 15:55:09,717 INFO    MainThread:9735 [wandb_run.py:_console_start():2458] atexit reg
2025-07-19 15:55:09,717 INFO    MainThread:9735 [wandb_run.py:_redirect():2306] redirect: wrap_raw
2025-07-19 15:55:09,717 INFO    MainThread:9735 [wandb_run.py:_redirect():2375] Wrapping output streams.
2025-07-19 15:55:09,718 INFO    MainThread:9735 [wandb_run.py:_redirect():2398] Redirects installed.
2025-07-19 15:55:09,721 INFO    MainThread:9735 [wandb_init.py:init():1075] run started, returning control to user process
2025-07-19 15:58:11,819 INFO    MsgRouterThr:9735 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
