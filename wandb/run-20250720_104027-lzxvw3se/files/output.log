
Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
eval every:100
step 0: train loss 10.9684, val loss 10.9694
merge_lora_weights 10.969396591186523 8.0 next_op['max_wait_iters']
iter 0: loss 10.9693, lr 0.00005, time 7400.29ms, mfu -100.00%
iter 10: loss 9.6202, lr 0.00055, time 531.15ms, mfu 34.79%
iter 20: loss 9.4645, lr 0.00104, time 546.92ms, mfu 34.69%
iter 30: loss 9.2749, lr 0.00154, time 559.34ms, mfu 34.53%
iter 40: loss 9.0924, lr 0.00204, time 560.35ms, mfu 34.37%
iter 50: loss 8.9928, lr 0.00254, time 562.18ms, mfu 34.22%
iter 60: loss 8.7850, lr 0.00303, time 566.82ms, mfu 34.06%
iter 70: loss 8.7404, lr 0.00353, time 574.31ms, mfu 33.87%
iter 80: loss 8.6741, lr 0.00403, time 577.87ms, mfu 33.68%
iter 90: loss 8.6199, lr 0.00453, time 583.09ms, mfu 33.48%
step 100: train loss 8.5657, val loss 8.5813
saving checkpoint to out
merge_lora_weights 8.581315994262695 8.0 next_op['max_wait_iters']
iter 100: loss 8.7751, lr 0.00502, time 4981.51ms, mfu 30.51%
iter 110: loss 8.4489, lr 0.00552, time 579.66ms, mfu 30.64%
iter 120: loss 8.3597, lr 0.00602, time 585.21ms, mfu 30.74%
iter 130: loss 8.3966, lr 0.00652, time 585.02ms, mfu 30.82%
iter 140: loss 8.2705, lr 0.00701, time 581.43ms, mfu 30.92%
iter 150: loss 8.2250, lr 0.00751, time 578.72ms, mfu 31.02%
iter 160: loss 8.2641, lr 0.00801, time 577.41ms, mfu 31.12%
iter 170: loss 8.0436, lr 0.00851, time 580.09ms, mfu 31.19%
iter 180: loss 8.0409, lr 0.00900, time 580.74ms, mfu 31.26%
iter 190: loss 8.0672, lr 0.00950, time 579.82ms, mfu 31.32%
step 200: train loss 7.9722, val loss 7.9741
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Loss threshold
Current val loss: 7.9741, Trigger loss: 8.0000
Iterations since last op: 200, Max wait: 500
Executing operation: merge_lora_weights first burn with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 17, with 8,202,240 parameters
num non-decayed parameter tensors: 7, with 5,376 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 28 parameters
Re-compiling the model...
Architectural operation completed successfully.
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_lr
Trigger reason: Loss threshold
Current val loss: 7.9741, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_lr  with value: 0.7
LR multiplier: 10.0000 -> 7.0000
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: reset_lr_schedule
Trigger reason: Loss threshold
Current val loss: 7.9741, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: reset_lr_schedule  with value: None
LR schedule offset: 0 -> 200
=== SCALING OPERATION COMPLETE ===

merge_lora_weights 7.974148750305176 7.2 next_op['max_wait_iters']
iter 200: loss 11.0377, lr 0.01000, time 4808.77ms, mfu 28.57%
iter 210: loss 8.3653, lr 0.00038, time 575.17ms, mfu 28.93%
iter 220: loss 8.0677, lr 0.00073, time 579.74ms, mfu 29.22%
iter 230: loss 7.8935, lr 0.00108, time 582.79ms, mfu 29.47%
iter 240: loss 7.8958, lr 0.00143, time 581.87ms, mfu 29.70%
iter 250: loss 7.8765, lr 0.00178, time 586.63ms, mfu 29.88%
iter 260: loss 7.7598, lr 0.00212, time 586.08ms, mfu 30.05%
iter 270: loss 7.7099, lr 0.00247, time 587.65ms, mfu 30.19%
iter 280: loss 7.7410, lr 0.00282, time 585.44ms, mfu 30.32%
iter 290: loss 7.7998, lr 0.00317, time 590.28ms, mfu 30.42%
step 300: train loss 7.7192, val loss 7.7327
saving checkpoint to out
merge_lora_weights 7.732706546783447 7.2 next_op['max_wait_iters']
iter 300: loss 7.7535, lr 0.00352, time 4765.15ms, mfu 27.77%
iter 310: loss 7.6200, lr 0.00387, time 584.54ms, mfu 28.15%
iter 320: loss 7.6939, lr 0.00421, time 588.48ms, mfu 28.48%
iter 330: loss 7.6256, lr 0.00456, time 588.86ms, mfu 28.77%
iter 340: loss 7.5971, lr 0.00491, time 584.26ms, mfu 29.05%
iter 350: loss 7.5503, lr 0.00526, time 582.55ms, mfu 29.32%
iter 360: loss 7.7152, lr 0.00561, time 584.16ms, mfu 29.55%
iter 370: loss 7.6462, lr 0.00596, time 585.81ms, mfu 29.75%
iter 380: loss 7.4931, lr 0.00630, time 589.97ms, mfu 29.91%
iter 390: loss 7.6242, lr 0.00665, time 585.92ms, mfu 30.07%
step 400: train loss 7.5569, val loss 7.5002
saving checkpoint to out
merge_lora_weights 7.500157833099365 7.2 next_op['max_wait_iters']
iter 400: loss 7.4499, lr 0.00700, time 5079.65ms, mfu 27.43%
iter 410: loss 7.6800, lr 0.00700, time 585.06ms, mfu 27.85%
iter 420: loss 7.4520, lr 0.00700, time 585.62ms, mfu 28.22%
iter 430: loss 7.4890, lr 0.00700, time 586.02ms, mfu 28.55%
iter 440: loss 7.4560, lr 0.00700, time 591.07ms, mfu 28.82%
iter 450: loss 7.3474, lr 0.00700, time 590.31ms, mfu 29.07%
iter 460: loss 7.3397, lr 0.00700, time 584.42ms, mfu 29.32%
iter 470: loss 7.3792, lr 0.00700, time 587.08ms, mfu 29.54%
iter 480: loss 7.2950, lr 0.00700, time 586.05ms, mfu 29.74%
iter 490: loss 7.4197, lr 0.00700, time 586.75ms, mfu 29.91%
step 500: train loss 7.3279, val loss 7.3689
saving checkpoint to out

=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: merge_lora_weights
Trigger reason: Timeout
Current val loss: 7.3689, Trigger loss: 7.2000
Iterations since last op: 300, Max wait: 300
Executing operation: merge_lora_weights second burn with value: None
Performing architectural operation: merge_lora_weights
Merging LoRA weights into main weights...
LoRA weights merged and reset.

Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 17, with 8,202,240 parameters
num non-decayed parameter tensors: 7, with 5,376 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 28 parameters
Re-compiling the model...
Architectural operation completed successfully.
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_lr
Trigger reason: Loss threshold
Current val loss: 7.3689, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_lr  with value: 0.7
LR multiplier: 7.0000 -> 4.9000
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_warmup_iters
Trigger reason: Loss threshold
Current val loss: 7.3689, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_warmup_iters  with value: 1.5
Warmup iters multiplier: 1.0000 -> 1.5000
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: reset_lr_schedule
Trigger reason: Loss threshold
Current val loss: 7.3689, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: reset_lr_schedule  with value: None
LR schedule offset: 200 -> 500
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_batch_size
Trigger reason: Loss threshold
Current val loss: 7.3689, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_batch_size  with value: 0.5
Batch size: 32 -> 16
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_grad_accum
Trigger reason: Loss threshold
Current val loss: 7.3689, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_grad_accum  with value: 2.0
Grad accum steps: 2 -> 4
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: change_lr
Trigger reason: Loss threshold
Current val loss: 7.3689, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: change_lr  with value: 0.7
LR multiplier: 4.9000 -> 3.4300
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: reset_lr_schedule
Trigger reason: Loss threshold
Current val loss: 7.3689, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: reset_lr_schedule  with value: None
LR schedule offset: 500 -> 500
=== SCALING OPERATION COMPLETE ===


=== SCALING OPERATION TRIGGERED (DDP SYNC) ===
Operation: stack_layers
Trigger reason: Loss threshold
Current val loss: 7.3689, Trigger loss: 100.0000
Iterations since last op: 0, Max wait: 1
Executing operation: stack_layers first resize with value: 2
Performing architectural operation: stack_layers
Stacking layers: current depth 3, creating 6 total layers.
Model now has 6 layers.

Detailed parameter count:
  total                  | Total:   63,213,312 | Trainable:   13,963,008
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:   15,040,512 | Trainable:    4,423,680
  feed_forward_layers    | Total:    7,077,888 | Trainable:    7,077,888
  layer_norms            | Total:        9,216 | Trainable:        9,216
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
Re-configuring optimizer after architectural change...
num decayed parameter tensors: 32, with 13,953,024 parameters
num non-decayed parameter tensors: 13, with 9,984 parameters
using fused AdamW: True
Transferring optimizer state for existing parameters...
Transferred optimizer state for 0 / 52 parameters
Re-compiling the model...
Architectural operation completed successfully.
Re-evaluating validation loss after operation...
New val loss after operation: 8.2586
iter 500: loss 8.0925, lr 0.00700, time 22225.71ms, mfu 27.03%
iter 510: loss 7.5108, lr 0.00013, time 761.72ms, mfu 27.43%
iter 520: loss 7.4073, lr 0.00024, time 775.29ms, mfu 27.73%
iter 530: loss 7.2919, lr 0.00035, time 782.68ms, mfu 27.97%
iter 540: loss 7.4411, lr 0.00047, time 780.02ms, mfu 28.20%
iter 550: loss 7.0958, lr 0.00058, time 786.12ms, mfu 28.38%
iter 560: loss 7.3459, lr 0.00070, time 772.70ms, mfu 28.60%
iter 570: loss 7.2223, lr 0.00081, time 770.09ms, mfu 28.81%
iter 580: loss 7.2263, lr 0.00092, time 761.21ms, mfu 29.03%
iter 590: loss 7.2164, lr 0.00104, time 772.41ms, mfu 29.18%
step 600: train loss 7.1455, val loss 7.1078
saving checkpoint to out
merge_lora_weights 7.107751369476318 6.8 next_op['max_wait_iters']
iter 600: loss 6.9454, lr 0.00115, time 3658.72ms, mfu 26.91%
iter 610: loss 6.9420, lr 0.00126, time 764.81ms, mfu 27.31%
iter 620: loss 6.9672, lr 0.00138, time 762.99ms, mfu 27.67%
iter 630: loss 6.8735, lr 0.00149, time 763.66ms, mfu 27.99%
iter 640: loss 6.9910, lr 0.00161, time 772.57ms, mfu 28.25%
iter 650: loss 6.9563, lr 0.00172, time 774.25ms, mfu 28.47%
iter 660: loss 6.9783, lr 0.00183, time 772.30ms, mfu 28.68%
iter 670: loss 6.9476, lr 0.00195, time 774.06ms, mfu 28.87%
iter 680: loss 6.9176, lr 0.00206, time 775.65ms, mfu 29.02%
iter 690: loss 7.0817, lr 0.00218, time 775.07ms, mfu 29.17%
step 700: train loss 6.9491, val loss 7.0796
saving checkpoint to out
merge_lora_weights 7.079598903656006 6.8 next_op['max_wait_iters']
iter 700: loss 6.9878, lr 0.00229, time 3283.55ms, mfu 26.97%
iter 710: loss 7.1040, lr 0.00240, time 772.30ms, mfu 27.33%
iter 720: loss 6.9390, lr 0.00252, time 769.99ms, mfu 27.66%
iter 730: loss 7.0450, lr 0.00263, time 770.71ms, mfu 27.96%
iter 740: loss 7.0892, lr 0.00275, time 771.24ms, mfu 28.22%
iter 750: loss 6.8254, lr 0.00286, time 773.79ms, mfu 28.45%
iter 760: loss 7.0488, lr 0.00297, time 768.24ms, mfu 28.68%
iter 770: loss 7.0245, lr 0.00309, time 769.35ms, mfu 28.88%
iter 780: loss 6.9276, lr 0.00320, time 770.80ms, mfu 29.06%
iter 790: loss 6.7644, lr 0.00332, time 770.38ms, mfu 29.22%
step 800: train loss 6.9247, val loss 6.9289
saving checkpoint to out
merge_lora_weights 6.928921699523926 6.8 next_op['max_wait_iters']
iter 800: loss 6.7899, lr 0.00343, time 3554.33ms, mfu 26.96%
iter 810: loss 6.7652, lr 0.00343, time 774.36ms, mfu 27.31%
iter 820: loss 6.9718, lr 0.00343, time 774.14ms, mfu 27.63%
iter 830: loss 7.1290, lr 0.00343, time 768.71ms, mfu 27.94%
iter 840: loss 6.8739, lr 0.00343, time 770.16ms, mfu 28.21%
iter 850: loss 6.7308, lr 0.00343, time 775.41ms, mfu 28.43%
iter 860: loss 6.7780, lr 0.00343, time 775.30ms, mfu 28.64%
iter 870: loss 6.7163, lr 0.00343, time 774.16ms, mfu 28.82%
iter 880: loss 6.9176, lr 0.00343, time 773.94ms, mfu 28.99%
iter 890: loss 6.6652, lr 0.00343, time 776.81ms, mfu 29.13%
step 900: train loss 6.9574, val loss 6.9048
saving checkpoint to out
merge_lora_weights 6.904757022857666 6.8 next_op['max_wait_iters']
iter 900: loss 6.6019, lr 0.00343, time 3701.36ms, mfu 26.86%
iter 910: loss 6.8976, lr 0.00343, time 770.63ms, mfu 27.23%
iter 920: loss 7.0760, lr 0.00343, time 775.35ms, mfu 27.55%
iter 930: loss 6.9564, lr 0.00343, time 777.29ms, mfu 27.84%
iter 940: loss 6.8503, lr 0.00343, time 770.53ms, mfu 28.12%
iter 950: loss 6.6739, lr 0.00343, time 774.34ms, mfu 28.35%
iter 960: loss 6.9449, lr 0.00343, time 773.42ms, mfu 28.57%
iter 970: loss 6.7308, lr 0.00343, time 771.39ms, mfu 28.78%
iter 980: loss 7.1315, lr 0.00343, time 771.25ms, mfu 28.96%
iter 990: loss 6.7539, lr 0.00343, time 770.24ms, mfu 29.13%
step 1000: train loss 6.7949, val loss 6.8158
saving checkpoint to out
merge_lora_weights 6.81580114364624 6.8 next_op['max_wait_iters']
iter 1000: loss 6.7282, lr 0.00343, time 3701.75ms, mfu 26.85%
iter 1010: loss 6.7577, lr 0.00343, time 766.02ms, mfu 27.25%
iter 1020: loss 6.6844, lr 0.00343, time 775.56ms, mfu 27.57%
iter 1030: loss 6.7355, lr 0.00343, time 779.85ms, mfu 27.84%
iter 1040: loss 6.9285, lr 0.00343, time 782.77ms, mfu 28.07%
iter 1050: loss 6.4310, lr 0.00343, time 779.76ms, mfu 28.29%
iter 1060: loss 6.9853, lr 0.00343, time 781.27ms, mfu 28.49%
iter 1070: loss 6.8486, lr 0.00343, time 777.05ms, mfu 28.67%
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 654, in <module>
    logits, loss = model(X, Y)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 655, in _fn
    return fn(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/teamspace/studios/this_studio/nanoGPT/model.py", line 420, in forward
    def forward(self, idx, targets=None):
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 838, in _fn
    return fn(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1201, in forward
    return compiled_fn(full_args)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 315, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 100, in g
    return f(*args)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/function.py", line 575, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 1937, in forward
    fw_outs = call_func_at_runtime_with_args(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 495, in wrapper
    return compiled_fn(runtime_args)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 689, in inner_fn
    outs = compiled_fn(args)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 460, in __call__
    return self.current_callable(inputs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2404, in run
    return model(new_inputs)
  File "/tmp/torchinductor_adamskrodzki/gq/cgqb3buidah25kvqnppvv67ykzzdrctw5te4xllqpokg6rqtr6ul.py", line 1884, in call
    triton_poi_fused__to_copy_t_7.run(primals_44, buf127, 589824, stream=stream0)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 956, in run
    return launcher(
  File "<string>", line 5, in launcher
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 529, in __call__
    self.launch(gridX, gridY, gridZ, stream, function, self.launch_cooperative_grid, global_scratch, *args)
KeyboardInterrupt
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 654, in <module>
    logits, loss = model(X, Y)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 655, in _fn
    return fn(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/teamspace/studios/this_studio/nanoGPT/model.py", line 420, in forward
    def forward(self, idx, targets=None):
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 838, in _fn
    return fn(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1201, in forward
    return compiled_fn(full_args)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 315, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 100, in g
    return f(*args)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/function.py", line 575, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 1937, in forward
    fw_outs = call_func_at_runtime_with_args(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 495, in wrapper
    return compiled_fn(runtime_args)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 689, in inner_fn
    outs = compiled_fn(args)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/output_code.py", line 460, in __call__
    return self.current_callable(inputs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/utils.py", line 2404, in run
    return model(new_inputs)
  File "/tmp/torchinductor_adamskrodzki/gq/cgqb3buidah25kvqnppvv67ykzzdrctw5te4xllqpokg6rqtr6ul.py", line 1884, in call
    triton_poi_fused__to_copy_t_7.run(primals_44, buf127, 589824, stream=stream0)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 956, in run
    return launcher(
  File "<string>", line 5, in launcher
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/triton/backends/nvidia/driver.py", line 529, in __call__
    self.launch(gridX, gridY, gridZ, stream, function, self.launch_cooperative_grid, global_scratch, *args)
KeyboardInterrupt
