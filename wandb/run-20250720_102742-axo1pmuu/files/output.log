
Detailed parameter count:
  total                  | Total:   52,149,504 | Trainable:    8,207,616
  token_embeddings       | Total:    2,451,456 | Trainable:    2,451,456
  position_embeddings    | Total:            0 | Trainable:            0
  attention_layers       | Total:    7,520,256 | Trainable:    2,211,840
  feed_forward_layers    | Total:    3,538,944 | Trainable:    3,538,944
  layer_norms            | Total:        4,608 | Trainable:        4,608
  final_layer_norm       | Total:          768 | Trainable:          768
  language_model_head    | Total:   38,633,472 | Trainable:            0
------------------------------------------------------------
step 0: train loss 10.9684, val loss 10.9694
iter 0: loss 10.9720, lr 0.00005, time 7013.50ms, mfu -100.00%
iter 10: loss 9.5939, lr 0.00055, time 560.79ms, mfu 32.95%
iter 20: loss 9.3624, lr 0.00104, time 560.13ms, mfu 32.96%
iter 30: loss 9.2448, lr 0.00154, time 571.47ms, mfu 32.90%
iter 40: loss 9.1000, lr 0.00204, time 575.22ms, mfu 32.82%
iter 50: loss 9.0173, lr 0.00254, time 570.96ms, mfu 32.77%
iter 60: loss 8.9298, lr 0.00303, time 579.02ms, mfu 32.69%
iter 70: loss 8.7244, lr 0.00353, time 578.52ms, mfu 32.61%
iter 80: loss 8.6844, lr 0.00403, time 579.96ms, mfu 32.54%
iter 90: loss 8.5933, lr 0.00453, time 574.96ms, mfu 32.50%
step 100: train loss 8.5839, val loss 8.5836
saving checkpoint to out
iter 100: loss 8.5305, lr 0.00502, time 4838.30ms, mfu 29.63%
iter 110: loss 8.4412, lr 0.00552, time 573.29ms, mfu 29.89%
iter 120: loss 8.3756, lr 0.00602, time 578.08ms, mfu 30.10%
iter 130: loss 8.3636, lr 0.00652, time 568.74ms, mfu 30.34%
iter 140: loss 8.3294, lr 0.00701, time 569.13ms, mfu 30.55%
iter 150: loss 8.2449, lr 0.00751, time 568.88ms, mfu 30.75%
iter 160: loss 8.0622, lr 0.00801, time 565.66ms, mfu 30.94%
iter 170: loss 8.1737, lr 0.00851, time 574.91ms, mfu 31.06%
iter 180: loss 8.0936, lr 0.00900, time 566.22ms, mfu 31.22%
iter 190: loss 7.9098, lr 0.00950, time 574.74ms, mfu 31.31%
step 200: train loss 7.9780, val loss 7.9816
saving checkpoint to out
iter 200: loss 7.9394, lr 0.01000, time 4982.83ms, mfu 28.55%
iter 210: loss 7.8606, lr 0.01000, time 576.59ms, mfu 28.90%
iter 220: loss 7.8996, lr 0.01000, time 581.99ms, mfu 29.19%
iter 230: loss 7.7438, lr 0.01000, time 580.58ms, mfu 29.45%
iter 240: loss 7.7048, lr 0.01000, time 582.51ms, mfu 29.68%
iter 250: loss 7.8966, lr 0.01000, time 578.64ms, mfu 29.90%
iter 260: loss 7.7388, lr 0.01000, time 583.52ms, mfu 30.08%
iter 270: loss 7.7915, lr 0.01000, time 579.16ms, mfu 30.26%
iter 280: loss 7.6940, lr 0.01000, time 579.85ms, mfu 30.42%
iter 290: loss 7.7341, lr 0.01000, time 578.77ms, mfu 30.57%
step 300: train loss 7.6390, val loss 7.6504
saving checkpoint to out
iter 300: loss 7.7224, lr 0.01000, time 5072.96ms, mfu 27.88%
iter 310: loss 7.7861, lr 0.01000, time 566.13ms, mfu 28.36%
iter 320: loss 7.4010, lr 0.01000, time 577.30ms, mfu 28.72%
iter 330: loss 7.4962, lr 0.01000, time 579.40ms, mfu 29.04%
iter 340: loss 7.6091, lr 0.01000, time 579.43ms, mfu 29.33%
iter 350: loss 7.5622, lr 0.01000, time 580.17ms, mfu 29.58%
iter 360: loss 7.3682, lr 0.01000, time 578.59ms, mfu 29.81%
iter 370: loss 7.5295, lr 0.01000, time 578.70ms, mfu 30.03%
iter 380: loss 7.4111, lr 0.01000, time 578.57ms, mfu 30.22%
iter 390: loss 7.5272, lr 0.01000, time 573.57ms, mfu 30.42%
step 400: train loss 7.4726, val loss 7.4011
saving checkpoint to out
iter 400: loss 7.4558, lr 0.01000, time 4978.27ms, mfu 27.75%
iter 410: loss 7.5479, lr 0.01000, time 573.15ms, mfu 28.20%
iter 420: loss 7.4096, lr 0.01000, time 580.51ms, mfu 28.56%
iter 430: loss 7.3919, lr 0.01000, time 578.86ms, mfu 28.90%
iter 440: loss 7.4644, lr 0.01000, time 580.31ms, mfu 29.19%
iter 450: loss 7.4068, lr 0.01000, time 578.81ms, mfu 29.47%
iter 460: loss 7.5850, lr 0.01000, time 581.35ms, mfu 29.70%
iter 470: loss 7.4347, lr 0.01000, time 578.02ms, mfu 29.93%
iter 480: loss 7.2840, lr 0.01000, time 580.15ms, mfu 30.12%
iter 490: loss 7.3183, lr 0.01000, time 579.23ms, mfu 30.30%
step 500: train loss 7.3092, val loss 7.3243
saving checkpoint to out
iter 500: loss 7.2725, lr 0.01000, time 4957.73ms, mfu 27.64%
iter 510: loss 7.5386, lr 0.01000, time 580.41ms, mfu 28.06%
iter 520: loss 7.4162, lr 0.01000, time 582.46ms, mfu 28.43%
iter 530: loss 7.2432, lr 0.01000, time 578.03ms, mfu 28.78%
iter 540: loss 7.2690, lr 0.01000, time 579.76ms, mfu 29.09%
iter 550: loss 7.3342, lr 0.01000, time 579.82ms, mfu 29.37%
iter 560: loss 7.3081, lr 0.01000, time 580.56ms, mfu 29.62%
iter 570: loss 7.2331, lr 0.01000, time 578.62ms, mfu 29.85%
iter 580: loss 7.2277, lr 0.01000, time 577.91ms, mfu 30.06%
iter 590: loss 7.1549, lr 0.01000, time 579.29ms, mfu 30.24%
step 600: train loss 7.1871, val loss 7.2445
saving checkpoint to out
iter 600: loss 7.2735, lr 0.01000, time 4677.21ms, mfu 27.62%
iter 610: loss 7.4076, lr 0.01000, time 575.48ms, mfu 28.07%
iter 620: loss 7.4436, lr 0.01000, time 579.00ms, mfu 28.45%
iter 630: loss 7.2932, lr 0.01000, time 579.27ms, mfu 28.80%
iter 640: loss 7.2022, lr 0.01000, time 577.59ms, mfu 29.12%
iter 650: loss 7.2686, lr 0.01000, time 578.59ms, mfu 29.40%
iter 660: loss 7.1897, lr 0.01000, time 581.81ms, mfu 29.63%
iter 670: loss 7.2184, lr 0.01000, time 581.58ms, mfu 29.85%
iter 680: loss 7.2932, lr 0.01000, time 577.83ms, mfu 30.06%
iter 690: loss 7.0091, lr 0.01000, time 582.75ms, mfu 30.23%
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 584, in <module>
    losses = estimate_loss()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 291, in estimate_loss
    losses[k] = loss.item()
KeyboardInterrupt
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 584, in <module>
    losses = estimate_loss()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/teamspace/studios/this_studio/nanoGPT/train.py", line 291, in estimate_loss
    losses[k] = loss.item()
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x767791ec88b0>
Traceback (most recent call last):
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/wandb/sdk/lib/service/service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/wandb/sdk/lib/service/service_connection.py", line 182, in teardown
    self._router.join()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt:
Exception ignored in atexit callback: <function shutdown_compile_workers at 0x76779d51c670>
Traceback (most recent call last):
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 113, in shutdown_compile_workers
    pool.shutdown()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 239, in shutdown
    self.process.wait(300)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/subprocess.py", line 1937, in _wait
    time.sleep(delay)
KeyboardInterrupt:
