_wandb:
    value:
        cli_version: 0.21.0
        e:
            63sic4jb43ymzrf53nhuqxp17ftn2z0e:
                args:
                    - config/train_gpt2.py
                codePath: train.py
                codePathLocal: train.py
                cpu_count: 4
                cpu_count_logical: 8
                cudaVersion: "12.2"
                disk:
                    /:
                        total: "395184570368"
                        used: "44596985856"
                email: adamskrodzki@gmail.com
                executable: /home/zeus/miniconda3/envs/cloudspace/bin/python
                git:
                    commit: d731303dd81c7c54a00f8bb057dcb7a2b2d5148c
                    remote: https://github.com/JinxCodesAI/nano_gpt.git
                gpu: NVIDIA L4
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ada
                      cudaCores: 7424
                      memoryTotal: "24152899584"
                      name: NVIDIA L4
                      uuid: GPU-5abc47f9-85a8-585a-d2e3-0ac0efb241d7
                host: cs-01k0fxfhg1c89yjb8skbz0g9n0
                memory:
                    total: "33652183040"
                os: Linux-6.8.0-1032-gcp-x86_64-with-glibc2.31
                program: /teamspace/studios/this_studio/nanoGPT/train.py
                python: CPython 3.10.10
                root: /teamspace/studios/this_studio/nanoGPT
                startedAt: "2025-07-18T23:36:46.669741Z"
                writerId: 63sic4jb43ymzrf53nhuqxp17ftn2z0e
        m: []
        python_version: 3.10.10
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
            "4": 3.10.10
            "5": 0.21.0
            "12": 0.21.0
            "13": linux-x86_64
always_save_checkpoint:
    value: true
backend:
    value: nccl
batch_size:
    value: 12
beta1:
    value: 0.9
beta2:
    value: 0.95
bias:
    value: false
block_size:
    value: 1024
compile:
    value: true
dataset:
    value: fineweb10B
decay_lr:
    value: true
device:
    value: cuda
dropout:
    value: 0
dtype:
    value: bfloat16
eval_interval:
    value: 1000
eval_iters:
    value: 1
eval_only:
    value: false
file_logging:
    value: true
grad_clip:
    value: 1
gradient_accumulation_steps:
    value: 40
init_from:
    value: scratch
learning_rate:
    value: 0.0006
log_dir:
    value: logs
log_interval:
    value: 10
lr_decay_iters:
    value: 600000
max_iters:
    value: 600000
min_lr:
    value: 6e-05
n_embd:
    value: 768
n_head:
    value: 12
n_layer:
    value: 12
out_dir:
    value: out
rotary_base:
    value: 10000
rotary_max_position_embeddings:
    value: 2048
use_rotary_embeddings:
    value: false
wandb_log:
    value: true
wandb_project:
    value: owt
wandb_run_name:
    value: gpt2-124M
warmup_iters:
    value: 2000
weight_decay:
    value: 0.1
