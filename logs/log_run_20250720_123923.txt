================================================================================
Training run started at 2025-07-20 12:39:23
================================================================================
Configuration:
----------------------------------------
always_save_checkpoint: True
attn_lora_rank: 48
attn_lora_rank_divisor: 16
backend: nccl
batch_size: 32
batch_size_multiplier: 1.0
beta1: 0.9
beta2: 0.95
bias: False
block_size: 1024
compile: True
dataset: fineweb10B
decay_lr: True
device: cuda
dropout: 0.0
dtype: bfloat16
embedding_mode: lora
embedding_rank: 48
eval_interval: 100
eval_interval_multiplier: 1.0
eval_iters: 10
eval_iters_multiplier: 1.0
eval_only: False
file_logging: True
grad_accum_multiplier: 1.0
grad_clip: 1.0
gradient_accumulation_steps: 2
init_from: scratch
learning_rate: 0.001
log_dir: logs
log_interval: 10
lora_alpha: 1.0
lora_alpha_multiplier: 1.0
lr_decay_iters: 600000
lr_multiplier: 10
max_iters: 600000
min_lr: 6e-05
n_embd: 768
n_head: 12
n_hidden_divisor: 4
n_layer: 12
n_layer_divisor: 4
out_dir: out
rotary_base: 10000.0
rotary_max_position_embeddings: 2048
use_rotary_embeddings: True
vocab_lora_rank_divisor: 16
wandb_log: True
wandb_project: owt
wandb_run_name: gpt2
warmup_iters: 200
warmup_iters_multiplier: 1.0
weight_decay: 0.1
----------------------------------------
[2025-07-20 12:39:33] step 0: train loss 10.9705, val loss 10.9694
[2025-07-20 12:40:35] step 100: train loss 8.5439, val loss 8.5786
[2025-07-20 12:41:35] step 200: train loss 7.9812, val loss 7.9733
[2025-07-20 12:41:36] OPERATION_START: merge_lora_weights first burn | iter=200 | value=None | trigger=Loss threshold | val_loss=7.9733 | trigger_loss=8.0000 | max_wait=500
[2025-07-20 12:41:36] OPERATION_SUCCESS: merge_lora_weights | iter=200 | status=merged
[2025-07-20 12:41:36] OPERATION_START: change_lr  | iter=200 | value=0.7 | trigger=Loss threshold | val_loss=7.9733 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:41:36] OPERATION_SUCCESS: change_lr | iter=200 | old=10 | new=7.0
[2025-07-20 12:41:36] OPERATION_START: reset_lr_schedule  | iter=200 | value=None | trigger=Loss threshold | val_loss=7.9733 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:41:36] OPERATION_SUCCESS: reset_lr_schedule | iter=200 | old=0 | new=200
[2025-07-20 12:42:37] step 300: train loss 7.7494, val loss 7.7403
[2025-07-20 12:43:38] step 400: train loss 7.5559, val loss 7.4931
[2025-07-20 12:44:39] step 500: train loss 7.3822, val loss 7.3583
[2025-07-20 12:44:40] OPERATION_START: merge_lora_weights second burn | iter=500 | value=None | trigger=Loss threshold | val_loss=7.3583 | trigger_loss=7.4000 | max_wait=300
[2025-07-20 12:44:40] OPERATION_SUCCESS: merge_lora_weights | iter=500 | status=merged
[2025-07-20 12:44:40] OPERATION_START: change_lr  | iter=500 | value=0.2 | trigger=Loss threshold | val_loss=7.3583 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:44:40] OPERATION_SUCCESS: change_lr | iter=500 | old=7.0 | new=1.4000000000000001
[2025-07-20 12:44:40] OPERATION_START: change_warmup_iters  | iter=500 | value=5 | trigger=Loss threshold | val_loss=7.3583 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:44:40] OPERATION_SUCCESS: change_warmup_iters | iter=500 | old=1.0 | new=5.0
[2025-07-20 12:44:40] OPERATION_START: reset_lr_schedule  | iter=500 | value=None | trigger=Loss threshold | val_loss=7.3583 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:44:40] OPERATION_SUCCESS: reset_lr_schedule | iter=500 | old=200 | new=500
[2025-07-20 12:44:40] OPERATION_START: change_batch_size  | iter=500 | value=0.5 | trigger=Loss threshold | val_loss=7.3583 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:44:40] OPERATION_SUCCESS: change_batch_size | iter=500 | old=32 | new=16
[2025-07-20 12:44:40] OPERATION_START: change_grad_accum  | iter=500 | value=2.0 | trigger=Loss threshold | val_loss=7.3583 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:44:40] OPERATION_SUCCESS: change_grad_accum | iter=500 | old=2 | new=4
[2025-07-20 12:44:40] OPERATION_START: change_lr  | iter=500 | value=0.7 | trigger=Loss threshold | val_loss=7.3583 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:44:40] OPERATION_SUCCESS: change_lr | iter=500 | old=1.4000000000000001 | new=0.98
[2025-07-20 12:44:40] OPERATION_START: reset_lr_schedule  | iter=500 | value=None | trigger=Loss threshold | val_loss=7.3583 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:44:40] OPERATION_SUCCESS: reset_lr_schedule | iter=500 | old=500 | new=500
[2025-07-20 12:44:40] OPERATION_START: decrease_vocab_lora_scaling first resize | iter=500 | value=2 | trigger=Loss threshold | val_loss=7.3583 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:44:41] OPERATION_SUCCESS: decrease_vocab_lora_scaling | iter=500 | old_divisor=16 | new_divisor=8.0 | new_rank=96
[2025-07-20 12:44:51] OPERATION_REEVALUATION: decrease_vocab_lora_scaling | iter=500 | old_val_loss=7.3583 | new_val_loss=7.6712 | change=+0.3129
[2025-07-20 12:44:51] step 500: train loss 7.7535, val loss 7.6712
[2025-07-20 12:46:05] step 600: train loss 7.1617, val loss 7.2594
[2025-07-20 12:47:03] step 700: train loss 7.2027, val loss 7.1620
[2025-07-20 12:48:01] step 800: train loss 7.1028, val loss 7.0612
[2025-07-20 12:48:59] step 900: train loss 7.0495, val loss 7.1310
[2025-07-20 12:49:57] step 1000: train loss 7.0432, val loss 7.0497
[2025-07-20 12:50:54] step 1100: train loss 6.9981, val loss 7.1258
[2025-07-20 12:51:52] step 1200: train loss 6.9735, val loss 6.9812
[2025-07-20 12:51:53] OPERATION_START: merge_lora_weights third burn | iter=1200 | value=None | trigger=Loss threshold | val_loss=6.9812 | trigger_loss=7.0000 | max_wait=700
[2025-07-20 12:51:53] OPERATION_SUCCESS: merge_lora_weights | iter=1200 | status=merged
[2025-07-20 12:51:53] OPERATION_START: change_batch_size  | iter=1200 | value=0.5 | trigger=Loss threshold | val_loss=6.9812 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:51:53] OPERATION_SUCCESS: change_batch_size | iter=1200 | old=16 | new=8
[2025-07-20 12:51:53] OPERATION_START: change_grad_accum  | iter=1200 | value=2.0 | trigger=Loss threshold | val_loss=6.9812 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:51:53] OPERATION_SUCCESS: change_grad_accum | iter=1200 | old=4 | new=8
[2025-07-20 12:51:53] OPERATION_START: decrease_vocab_lora_scaling  | iter=1200 | value=0.5 | trigger=Loss threshold | val_loss=6.9812 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:51:53] OPERATION_SUCCESS: decrease_vocab_lora_scaling | iter=1200 | old_divisor=8.0 | new_divisor=16.0 | new_rank=48
[2025-07-20 12:52:02] OPERATION_REEVALUATION: decrease_vocab_lora_scaling | iter=1200 | old_val_loss=6.9812 | new_val_loss=7.0175 | change=+0.0363
[2025-07-20 12:52:02] step 1200: train loss 6.9427, val loss 7.0175
[2025-07-20 12:53:13] step 1300: train loss 6.8636, val loss 7.0104
[2025-07-20 12:53:14] OPERATION_START: change_lr  | iter=1300 | value=0.7 | trigger=Loss threshold | val_loss=7.0104 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:53:14] OPERATION_SUCCESS: change_lr | iter=1300 | old=0.98 | new=0.6859999999999999
[2025-07-20 12:53:14] OPERATION_START: reset_lr_schedule  | iter=1300 | value=None | trigger=Loss threshold | val_loss=7.0104 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:53:14] OPERATION_SUCCESS: reset_lr_schedule | iter=1300 | old=500 | new=1300
[2025-07-20 12:53:14] OPERATION_START: stack_layers third resize | iter=1300 | value=2 | trigger=Loss threshold | val_loss=7.0104 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 12:53:14] OPERATION_SUCCESS: stack_layers | iter=1300 | old_divisor=4 | new_divisor=2.0 | new_layers=6
[2025-07-20 12:53:26] OPERATION_REEVALUATION: stack_layers | iter=1300 | old_val_loss=7.0104 | new_val_loss=7.6430 | change=+0.6326
[2025-07-20 12:53:26] step 1300: train loss 7.6060, val loss 7.6430
[2025-07-20 12:55:05] step 1400: train loss 7.0379, val loss 7.0471
[2025-07-20 12:56:22] step 1500: train loss 7.0523, val loss 6.9026
[2025-07-20 12:57:40] step 1600: train loss 6.9979, val loss 6.9349
[2025-07-20 12:58:58] step 1700: train loss 6.8847, val loss 6.9038
[2025-07-20 13:00:16] step 1800: train loss 6.8979, val loss 6.9017
[2025-07-20 13:01:34] step 1900: train loss 6.8594, val loss 6.9280
[2025-07-20 13:01:35] OPERATION_START: merge_lora_weights fourth burn | iter=1900 | value=None | trigger=Timeout | val_loss=6.9280 | trigger_loss=6.0000 | max_wait=600
[2025-07-20 13:01:35] OPERATION_SUCCESS: merge_lora_weights | iter=1900 | status=merged
[2025-07-20 13:01:35] OPERATION_START: widen_mlp second resize | iter=1900 | value=2 | trigger=Loss threshold | val_loss=6.9280 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 13:01:35] OPERATION_SUCCESS: widen_mlp | iter=1900 | old_divisor=4 | new_divisor=2.0 | new_hidden=1536
[2025-07-20 13:01:47] OPERATION_REEVALUATION: widen_mlp | iter=1900 | old_val_loss=6.9280 | new_val_loss=6.9137 | change=-0.0144
[2025-07-20 13:01:47] step 1900: train loss 6.8171, val loss 6.9137
[2025-07-20 13:03:32] step 2000: train loss 6.8312, val loss 6.8515
[2025-07-20 13:03:33] OPERATION_START: change_batch_size  | iter=2000 | value=0.5 | trigger=Loss threshold | val_loss=6.8515 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 13:03:33] OPERATION_SUCCESS: change_batch_size | iter=2000 | old=8 | new=4
[2025-07-20 13:03:33] OPERATION_START: change_grad_accum  | iter=2000 | value=2.0 | trigger=Loss threshold | val_loss=6.8515 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 13:03:33] OPERATION_SUCCESS: change_grad_accum | iter=2000 | old=8 | new=16
[2025-07-20 13:03:33] OPERATION_START: widen_mlp fourth resize | iter=2000 | value=2 | trigger=Loss threshold | val_loss=6.8515 | trigger_loss=100.0000 | max_wait=1
[2025-07-20 13:03:34] OPERATION_SUCCESS: widen_mlp | iter=2000 | old_divisor=2.0 | new_divisor=1.0 | new_hidden=3072
