================================================================================
Training run started at 2025-07-19 00:25:22
================================================================================
Configuration:
----------------------------------------
always_save_checkpoint: True
backend: nccl
batch_size: 12
beta1: 0.9
beta2: 0.95
bias: False
block_size: 1024
compile: True
dataset: fineweb10B
decay_lr: True
device: cuda
dropout: 0.0
dtype: bfloat16
eval_interval: 50
eval_iters: 1
eval_only: False
file_logging: True
grad_clip: 1.0
gradient_accumulation_steps: 5
init_from: scratch
learning_rate: 0.0006
log_dir: logs
log_interval: 10
lr_decay_iters: 600000
max_iters: 600000
min_lr: 6e-05
n_embd: 192
n_head: 12
n_layer: 12
out_dir: out
rotary_base: 10000.0
rotary_max_position_embeddings: 2048
use_rotary_embeddings: True
wandb_log: True
wandb_project: owt
wandb_run_name: gpt2-124M
warmup_iters: 2000
weight_decay: 0.1
----------------------------------------
[2025-07-19 00:25:31] step 0: train loss 10.8452, val loss 10.8523
[2025-07-19 00:25:52] step 50: train loss 10.4409, val loss 10.4469
[2025-07-19 00:26:11] step 100: train loss 10.1542, val loss 10.1227
[2025-07-19 00:26:31] step 150: train loss 9.7124, val loss 9.7816
[2025-07-19 00:26:50] step 200: train loss 9.2773, val loss 9.1563
[2025-07-19 00:27:09] step 250: train loss 8.7484, val loss 8.7163
[2025-07-19 00:27:28] step 300: train loss 8.1046, val loss 8.1914
[2025-07-19 00:27:48] step 350: train loss 7.8182, val loss 7.5410
[2025-07-19 00:28:07] step 400: train loss 7.2790, val loss 7.3857
[2025-07-19 00:28:26] step 450: train loss 7.0385, val loss 6.9199
[2025-07-19 00:28:46] step 500: train loss 6.8231, val loss 6.8590
[2025-07-19 00:29:05] step 550: train loss 6.5082, val loss 6.7747
[2025-07-19 00:29:24] step 600: train loss 6.5789, val loss 6.6491
[2025-07-19 00:29:44] step 650: train loss 6.2877, val loss 6.4924
[2025-07-19 00:30:03] step 700: train loss 6.4584, val loss 6.4342
[2025-07-19 00:30:23] step 750: train loss 6.3724, val loss 6.3221
[2025-07-19 00:30:42] step 800: train loss 6.1408, val loss 6.5034
[2025-07-19 00:31:02] step 850: train loss 6.1571, val loss 6.0985
[2025-07-19 00:31:21] step 900: train loss 6.1174, val loss 6.1375
[2025-07-19 00:31:41] step 950: train loss 6.1381, val loss 6.0482
[2025-07-19 00:32:00] step 1000: train loss 6.2660, val loss 6.0181
[2025-07-19 00:32:20] step 1050: train loss 5.8982, val loss 5.8306
[2025-07-19 00:32:39] step 1100: train loss 5.9552, val loss 5.7570
[2025-07-19 00:32:59] step 1150: train loss 5.8163, val loss 5.6361
[2025-07-19 00:33:18] step 1200: train loss 5.6313, val loss 5.6530
[2025-07-19 00:33:38] step 1250: train loss 5.6752, val loss 5.7109
[2025-07-19 00:33:57] step 1300: train loss 5.6441, val loss 5.6202
[2025-07-19 00:34:16] step 1350: train loss 5.4683, val loss 5.6853
[2025-07-19 00:34:36] step 1400: train loss 5.5310, val loss 5.5374
